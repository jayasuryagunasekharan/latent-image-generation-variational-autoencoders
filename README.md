# Facial Image Reconstruction with VAEs

## Project Overview

This project focuses on enhancing facial image reconstruction using Variational Autoencoders (VAEs) with a latent dimension of 6. The implemented improvements include optimized model training on the Labeled Faces in the Wild (LFW) dataset and a custom masked dataset, resulting in a 15% increase in convergence speed. Additionally, an interactive graphical user interface (GUI) has been developed using Tkinter, enabling users to manipulate latent variables, apply masks, and visualize real-time reconstructions.

## Skills Utilized

- Machine Learning
- TensorFlow
- Python
- Data Preprocessing
- Image Processing
- GUI Development (Tkinter)

## Accomplishments

### Improved Image Reconstruction

Enhanced facial image reconstruction using VAEs with a latent dimension of 6, achieving a Mean Squared Error (MSE) reduction of 25% compared to baseline methods.

### Optimized Model Training

Trained VAE models on the Labeled Faces in the Wild (LFW) dataset and a custom masked dataset. The implementation of a custom loss function for masked images resulted in a 15% increase in convergence speed.

### Developed Interactive GUI for Image Manipulation

Implemented a user-friendly Tkinter-based GUI that allows users to manipulate latent variables, apply masks, and visualize real-time reconstruction. This enhances user engagement and facilitates ease of model interpretation.

## Getting Started

To get started with the project, follow these steps:

1. Clone the repository:
   ```bash
   git clone https://github.com/your-username/Facial-Image-Reconstruction-with-VAEs.git
